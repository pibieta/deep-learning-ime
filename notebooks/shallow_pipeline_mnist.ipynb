{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJWCAHXN15Zi"
      },
      "source": [
        "# Comparação de Classificadores\n",
        "\n",
        "Classificadores a serem testados: KNN, SVM linear, SVM RBF, Decision Tree, Random Forest e Neural Network.\n",
        "\n",
        "Métrica de avaliação: Accuracy, Confusion Matrix.\n",
        "\n",
        "Links úteis:\n",
        "\n",
        "http://scikit-learn.org/stable/modules/classes.html\n",
        "\n",
        "http://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating scikit-image.\n",
        "!pip install -U scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A168iUKXTaP_",
        "outputId": "37d7f02f-2f7b-410b-d7d3-e70562414842"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.18.3)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.7.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.8.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "Successfully installed scikit-image-0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z_QnP-zY15Zy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "\n",
        "from skimage.feature import hog, daisy\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def mount_dataset(dataset, n_samples):\n",
        "\n",
        "    img_list = []\n",
        "    feat_list = []\n",
        "    lab_list = []\n",
        "\n",
        "    # Iterating over a subset of 1000 training images and extracting features.\n",
        "    for i in range(n_samples):\n",
        "\n",
        "        img = np.array(dataset[i][0]) # From PIL to numpy image.\n",
        "        lab = dataset[i][1] # Recovering sample label.\n",
        "\n",
        "        # Linearized pixels as features (naive).\n",
        "        feat = img.ravel()\n",
        "\n",
        "        '''TO DO: Extraia características usando descritores mais representativos\n",
        "        que os pixels linearizados (i.e. HOG, Daisy).'''\n",
        "\n",
        "        feat = feat.ravel()\n",
        "\n",
        "        # Updating lists.\n",
        "        img_list.append(img)\n",
        "        feat_list.append(feat)\n",
        "        lab_list.append(lab)\n",
        "\n",
        "    imgs = np.asarray(img_list)\n",
        "    feats = np.asarray(feat_list)\n",
        "    labs = np.asarray(lab_list)\n",
        "\n",
        "    return imgs, feats, labs\n",
        "\n",
        "# Classifier names.\n",
        "names = [\n",
        "    'KNN',\n",
        "    'Naive Bayes',\n",
        "]\n",
        "\n",
        "# Presetting classifiers.\n",
        "'''TO DO: Instancie os outros classificadores descritos no cabeçalho desse\n",
        "notebook. Lembre-se de adicionar o nome do classificador na lista `names'\n",
        "e de importar os pacotes necessários (i.e. sklearn.ensemble, sklearn.svm,\n",
        "etc). Para mais informações sobre os algoritmos de classificação do sklearn:\n",
        "<https://scikit-learn.org/stable/supervised_learning.html>'''\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(n_neighbors=5),\n",
        "    GaussianNB(),\n",
        "]\n",
        "\n",
        "'''TO DO: Modifique os parâmetros dos algoritmos e insira novos classificadores\n",
        "modernos (i.e. AdaBoost, Quadratic Discriminant Analysis, XGBoost, etc).'''\n",
        "\n",
        "# Instantiating datasets from torchvision.\n",
        "trn_dataset = MNIST(root='./',\n",
        "                    train=True,\n",
        "                    download=True)\n",
        "tst_dataset = MNIST(root='./',\n",
        "                    train=False)\n",
        "n_classes = 10\n",
        "\n",
        "''' TO DO: Teste em outros datasets um pouco mais desafiadores como o EMNIST,\n",
        "KMNIST e FasionMNIST. Todos eles estão disponiveis no torchvision com uso bem\n",
        "similar à interface do MNIST. Para mais informações sobre como carregar\n",
        "datasets do pytorch, acesse:\n",
        "<https://pytorch.org/tutorials/beginner/basics/data_tutorial.html>'''\n",
        "\n",
        "# Recovering training and test sets.\n",
        "trn_imgs, trn_feats, trn_labs = mount_dataset(trn_dataset, n_samples=1000)\n",
        "tst_imgs, tst_feats, tst_labs = mount_dataset(tst_dataset, n_samples=1000)\n",
        "\n",
        "'''TO DO: Teste com 100, 1000 e 10000 samples no treino. Observe como se\n",
        "comportam os diferentes algoritmos de aprendizado com mais e menos amostras.'''\n",
        "\n",
        "'''TO DO: Separe 20% do conjunto de treino para realizar validação e execute um\n",
        "grid search para achar os melhores parâmetros de cada classificador.'''\n",
        "\n",
        "print('Training set')\n",
        "print('    image tensor', trn_imgs.shape)\n",
        "print('    feature tensor', trn_feats.shape)\n",
        "print('    label tensor', trn_labs.shape)\n",
        "\n",
        "print('Test set')\n",
        "print('    image tensor', tst_imgs.shape)\n",
        "print('    feature tensor', tst_feats.shape)\n",
        "print('    label tensor', tst_labs.shape)\n",
        "\n",
        "# Iterate over classifiers.\n",
        "for clf_cnt, (clf_name, clf) in enumerate(zip(names, classifiers)):\n",
        "    \n",
        "    print('------------------------------------')\n",
        "    print('------------------------------------')\n",
        "    print('------------------------------------')\n",
        "    print('    ', 'Classifier', clf_name)\n",
        "    \n",
        "    # Fitting classifier to train data.\n",
        "    clf.fit(trn_feats, trn_labs)\n",
        "    \n",
        "    # Obtaining class prediction for training data.\n",
        "    prd_trn = clf.predict(trn_feats)\n",
        "    \n",
        "    # Obtaining class prediction for unseen data.\n",
        "    prd_tst = clf.predict(tst_feats)\n",
        "    \n",
        "    # Computing error metrics in the training data.\n",
        "    acc_trn = metrics.accuracy_score(trn_labs, prd_trn)\n",
        "    cm_trn = metrics.confusion_matrix(trn_labs, prd_trn, normalize='true')\n",
        "    \n",
        "    # Computing error metrics in the unseen data.\n",
        "    acc_tst = metrics.accuracy_score(tst_labs, prd_tst)\n",
        "    cm_tst = metrics.confusion_matrix(tst_labs, prd_tst, normalize='true')\n",
        "    \n",
        "    # Printing error metrics.\n",
        "    print('        Accuracy Train: %.4f, Test: %.4f' % (acc_trn, acc_tst))\n",
        "\n",
        "    # Displaying confusion matrices.\n",
        "    disp_trn = metrics.ConfusionMatrixDisplay(confusion_matrix=cm_trn,\n",
        "                                              display_labels=[str(i) for i in range(n_classes)])\n",
        "    disp_tst = metrics.ConfusionMatrixDisplay(confusion_matrix=cm_tst,\n",
        "                                              display_labels=[str(i) for i in range(n_classes)])\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "    \n",
        "    disp_trn.plot(ax=ax[0])\n",
        "    ax[0].set_title('Train')\n",
        "    \n",
        "    disp_tst.plot(ax=ax[1])\n",
        "    ax[1].set_title('Test')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "    '''TO DO: Avalie a partir das métricas disponíveis os desempenhos dos\n",
        "    algoritmos nos conjuntos de treino e teste, observando quais algoritmos\n",
        "    com quais parâmetros eles overfitaram ou underfitaram.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_show_samples = 10\n",
        "\n",
        "perm = np.random.permutation(tst_feats.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(n_show_samples, len(classifiers), figsize=(3 * len(classifiers), 3 * n_show_samples))\n",
        "\n",
        "# Iterating over classifiers.\n",
        "for clf_cnt, (clf_name, clf) in enumerate(zip(names, classifiers)):\n",
        "    \n",
        "    # Predicting from subset of `n_show_samples' samples.\n",
        "    tst_prds = clf.predict(tst_feats[perm[:n_show_samples], :])\n",
        "    \n",
        "    # Plotting images.\n",
        "    for i in range(tst_prds.shape[0]):\n",
        "        \n",
        "        img = tst_imgs[perm[i]]\n",
        "        lab = tst_labs[perm[i]]\n",
        "        prd = tst_prds[i]\n",
        "\n",
        "        ax[i, clf_cnt].imshow(img, cmap='gray')\n",
        "        ax[i, clf_cnt].set_yticks([])\n",
        "        ax[i, clf_cnt].set_xticks([])\n",
        "        ax[i, clf_cnt].set_title('%s: Class %d, Pred %d' % (clf_name, lab, prd))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0O5FjknEeWQA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}